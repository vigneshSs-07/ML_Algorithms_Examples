{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1           0   \n",
       "1         1  38.0  71.2833         1         0         0           1   \n",
       "2         1  26.0   7.9250         0         0         1           1   \n",
       "3         1  35.0  53.1000         1         0         0           1   \n",
       "4         0  35.0   8.0500         0         0         1           0   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0         1        0        1  ...        1        0        0        0   \n",
       "1         0        0        1  ...        1        0        0        0   \n",
       "2         0        1        0  ...        1        0        0        0   \n",
       "3         0        0        1  ...        1        0        0        0   \n",
       "4         1        1        0  ...        1        0        0        0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        0           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        0           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20eb159d9c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Survived'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 24), (891,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seperating independent and dependent variables\n",
    "x = data.drop(['Survived'], axis=1)\n",
    "y = data['Survived']\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the train test split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y = train_test_split(x,y, random_state = 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.371701</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.152164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.412821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0  0.371701  0.024350       0.0       0.0       1.0         1.0       0.0   \n",
       "1  0.334004  0.016908       0.0       0.0       1.0         0.0       1.0   \n",
       "2  0.396833  0.015127       0.0       0.0       1.0         0.0       1.0   \n",
       "3  0.786378  0.152164       1.0       0.0       0.0         1.0       0.0   \n",
       "4  0.334004  0.412821       1.0       0.0       0.0         0.0       1.0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "1      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      0.0  ...      0.0      0.0      1.0      0.0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2      0.0      0.0      0.0         0.0         1.0         0.0  \n",
       "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_scaled = scaler.fit_transform(train_x)\n",
    "train_x_scaled = pd.DataFrame(train_x_scaled, columns=cols)\n",
    "train_x_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.143462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.359135</td>\n",
       "      <td>0.129995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.367921</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.346569</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.371701</td>\n",
       "      <td>0.054164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0  0.396833  0.143462       0.0       1.0       0.0         0.0       1.0   \n",
       "1  0.359135  0.129995       1.0       0.0       0.0         0.0       1.0   \n",
       "2  0.367921  0.014110       0.0       0.0       1.0         0.0       1.0   \n",
       "3  0.346569  0.025374       0.0       1.0       0.0         1.0       0.0   \n",
       "4  0.371701  0.054164       1.0       0.0       0.0         0.0       1.0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0      0.0      0.0      1.0  ...      1.0      0.0      0.0      0.0   \n",
       "1      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_scaled = scaler.transform(test_x)\n",
    "test_x_scaled = pd.DataFrame(test_x_scaled, columns=cols)\n",
    "test_x_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Logistic Regression and metric F1-score\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VigneshSS\\Anaconda3\\envs\\new_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating instance of Logistic Regresssion\n",
    "logreg = LogReg()\n",
    "\n",
    "# Fitting the model\n",
    "logreg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting over the Train\n",
    "train_predict = logreg.predict(train_x)\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training f1_score 0.7554671968190854\n"
     ]
    }
   ],
   "source": [
    "# Calculating f1-score\n",
    "k = f1_score(train_predict, train_y)\n",
    "print('Training f1_score', k )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score     0.7500000000000001\n"
     ]
    }
   ],
   "source": [
    "# Predicting over the Test Set and f1-score\n",
    "test_predict = logreg.predict(test_x)\n",
    "k = f1_score(test_predict, test_y)\n",
    "print('Test f1_score    ', k )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51588994, 0.48411006],\n",
       "       [0.9061611 , 0.0938389 ],\n",
       "       [0.87148895, 0.12851105],\n",
       "       ...,\n",
       "       [0.22892071, 0.77107929],\n",
       "       [0.31938475, 0.68061525],\n",
       "       [0.0450814 , 0.9549186 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting over the Train\n",
    "train_predict = logreg.predict_proba(train_x)\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48411006, 0.0938389 , 0.12851105, 0.78497297, 0.6355183 ,\n",
       "       0.11586216, 0.84315633, 0.77126711, 0.53804719, 0.08437062,\n",
       "       0.1058325 , 0.08614071, 0.12298241, 0.09656517, 0.60836609,\n",
       "       0.08518602, 0.31381307, 0.11932379, 0.0728184 , 0.28367102,\n",
       "       0.10375727, 0.21801306, 0.07489365, 0.58556452, 0.09079613,\n",
       "       0.51462476, 0.08598623, 0.55486204, 0.60616007, 0.12699391,\n",
       "       0.81954107, 0.08617763, 0.59304692, 0.13751797, 0.02376095,\n",
       "       0.58146584, 0.2170683 , 0.12577254, 0.0601951 , 0.28029493,\n",
       "       0.84453967, 0.39363636, 0.21168087, 0.70162768, 0.48284238,\n",
       "       0.94169493, 0.36467866, 0.23257725, 0.16533752, 0.89546046,\n",
       "       0.13100128, 0.63680303, 0.2357346 , 0.61273164, 0.34345662,\n",
       "       0.64332321, 0.77588772, 0.2872013 , 0.10886415, 0.31083252,\n",
       "       0.58174161, 0.2872013 , 0.12465255, 0.45786824, 0.10612971,\n",
       "       0.97596317, 0.11628988, 0.08614071, 0.86032821, 0.66195296,\n",
       "       0.9321215 , 0.7409277 , 0.89399676, 0.44889997, 0.83610247,\n",
       "       0.24293141, 0.86034502, 0.54003064, 0.55262639, 0.12699391,\n",
       "       0.52299452, 0.12647645, 0.1290851 , 0.02048113, 0.68549987,\n",
       "       0.94282575, 0.67693285, 0.07756887, 0.27349092, 0.93352442,\n",
       "       0.28512618, 0.13752547, 0.09224782, 0.13752547, 0.21168087,\n",
       "       0.9113643 , 0.34616196, 0.12298923, 0.55411396, 0.56578125,\n",
       "       0.13752547, 0.12307264, 0.09950382, 0.12820973, 0.1259956 ,\n",
       "       0.05480557, 0.31374198, 0.04372596, 0.74640809, 0.3083171 ,\n",
       "       0.2357346 , 0.43534997, 0.12577113, 0.13778116, 0.53974736,\n",
       "       0.32977659, 0.12753094, 0.92452287, 0.11248558, 0.13864759,\n",
       "       0.49761503, 0.4659003 , 0.21955595, 0.4017764 , 0.93476215,\n",
       "       0.3232013 , 0.38310398, 0.61263841, 0.13751646, 0.67261994,\n",
       "       0.09178012, 0.09660609, 0.39370895, 0.90578292, 0.12577113,\n",
       "       0.0300485 , 0.47828982, 0.06733661, 0.38873166, 0.90746274,\n",
       "       0.92975793, 0.13236534, 0.63887275, 0.10395557, 0.24489767,\n",
       "       0.25399602, 0.10909176, 0.92924939, 0.87048095, 0.90641765,\n",
       "       0.51457098, 0.47212475, 0.65193586, 0.07300855, 0.45225748,\n",
       "       0.0861926 , 0.44593014, 0.28039991, 0.09604419, 0.79463371,\n",
       "       0.30173381, 0.27349092, 0.32122093, 0.65661032, 0.04816552,\n",
       "       0.26542978, 0.11936374, 0.82504965, 0.34139931, 0.93814197,\n",
       "       0.05309068, 0.75905637, 0.61112675, 0.27493408, 0.32220429,\n",
       "       0.47579573, 0.50689593, 0.3839424 , 0.08316194, 0.09078569,\n",
       "       0.0826958 , 0.25227123, 0.04677088, 0.11495282, 0.92443015,\n",
       "       0.35934585, 0.9305989 , 0.29143634, 0.26019613, 0.16893705,\n",
       "       0.14454936, 0.05724336, 0.5686438 , 0.32570476, 0.12297421,\n",
       "       0.17649348, 0.2872013 , 0.90281236, 0.63253266, 0.26787798,\n",
       "       0.45360377, 0.40828761, 0.61263841, 0.11244764, 0.22040799,\n",
       "       0.88665063, 0.6132841 , 0.08405829, 0.77180991, 0.13752547,\n",
       "       0.61167084, 0.61263841, 0.12577254, 0.15758211, 0.94405531,\n",
       "       0.08614071, 0.07534213, 0.90459626, 0.61119402, 0.13444741,\n",
       "       0.11945168, 0.31675366, 0.08617763, 0.89036719, 0.22298942,\n",
       "       0.1620501 , 0.08614071, 0.71982878, 0.46536277, 0.14036786,\n",
       "       0.72683622, 0.46512337, 0.08773491, 0.26542978, 0.16669189,\n",
       "       0.7346948 , 0.38186084, 0.87790333, 0.11224293, 0.03883635,\n",
       "       0.24591504, 0.08630577, 0.2170683 , 0.1305979 , 0.64362002,\n",
       "       0.09656517, 0.66260577, 0.2357346 , 0.53227893, 0.11648403,\n",
       "       0.92066148, 0.09947716, 0.66846116, 0.8016374 , 0.95869378,\n",
       "       0.14934461, 0.37878782, 0.13109939, 0.08614071, 0.44852383,\n",
       "       0.04516918, 0.62681821, 0.0884178 , 0.12465116, 0.92605708,\n",
       "       0.31738171, 0.56153977, 0.08021588, 0.08617763, 0.08611179,\n",
       "       0.72261548, 0.13755404, 0.84179938, 0.66249547, 0.48121504,\n",
       "       0.28069728, 0.33772276, 0.08060727, 0.30018679, 0.35359361,\n",
       "       0.06621377, 0.11586216, 0.61262635, 0.08806712, 0.09772574,\n",
       "       0.44546058, 0.04991263, 0.85243248, 0.09361502, 0.81713132,\n",
       "       0.90480111, 0.55041088, 0.94078953, 0.09340343, 0.0313573 ,\n",
       "       0.94856403, 0.05837209, 0.32363754, 0.64128768, 0.11240212,\n",
       "       0.52801586, 0.43250359, 0.24105582, 0.10602125, 0.12315471,\n",
       "       0.04359951, 0.06810169, 0.30087998, 0.09079613, 0.79405398,\n",
       "       0.61263841, 0.45301002, 0.09934045, 0.2357346 , 0.08788106,\n",
       "       0.12577113, 0.11240843, 0.18957861, 0.11592317, 0.54832796,\n",
       "       0.34714831, 0.13447054, 0.80934522, 0.94623993, 0.4453208 ,\n",
       "       0.32363754, 0.587959  , 0.08605796, 0.13032192, 0.2437474 ,\n",
       "       0.11940237, 0.13752547, 0.02376095, 0.25624812, 0.08614071,\n",
       "       0.16352579, 0.09850929, 0.23352986, 0.8182997 , 0.05482527,\n",
       "       0.28564743, 0.93849384, 0.0780608 , 0.07063101, 0.38201403,\n",
       "       0.42305464, 0.63491416, 0.0428052 , 0.19572718, 0.50057667,\n",
       "       0.35716238, 0.12863522, 0.79553793, 0.29230919, 0.46700574,\n",
       "       0.80525786, 0.06523096, 0.15058444, 0.12721685, 0.25380655,\n",
       "       0.89729103, 0.62856792, 0.12699391, 0.27241799, 0.4668065 ,\n",
       "       0.80439197, 0.19446548, 0.08617763, 0.87458684, 0.96032228,\n",
       "       0.74378797, 0.92984432, 0.20449999, 0.66260577, 0.25915675,\n",
       "       0.42705418, 0.39821129, 0.04684586, 0.74421404, 0.85977902,\n",
       "       0.11821679, 0.73183972, 0.46023749, 0.13752547, 0.13896913,\n",
       "       0.93423651, 0.2357346 , 0.30697284, 0.31274432, 0.58855118,\n",
       "       0.4183539 , 0.35894154, 0.85968314, 0.08600117, 0.08617763,\n",
       "       0.80439197, 0.64325726, 0.06887876, 0.11248558, 0.55665479,\n",
       "       0.74781272, 0.76424403, 0.90314047, 0.4952917 , 0.12626935,\n",
       "       0.11474447, 0.3827391 , 0.10489278, 0.88435739, 0.39121743,\n",
       "       0.11038448, 0.55262639, 0.25370802, 0.11561187, 0.05838881,\n",
       "       0.46361056, 0.96393632, 0.92156794, 0.57088009, 0.85006042,\n",
       "       0.46904885, 0.61307153, 0.69339544, 0.25636902, 0.81053184,\n",
       "       0.17440835, 0.94434004, 0.10582052, 0.08572076, 0.0707109 ,\n",
       "       0.62679202, 0.86042484, 0.09145521, 0.06430323, 0.47285323,\n",
       "       0.61263841, 0.23664309, 0.1948288 , 0.58504693, 0.22750221,\n",
       "       0.18268033, 0.08018784, 0.6550858 , 0.31581279, 0.62471751,\n",
       "       0.70591907, 0.91380153, 0.82647737, 0.93001266, 0.76943218,\n",
       "       0.53700239, 0.13072824, 0.08614071, 0.08773491, 0.16374724,\n",
       "       0.54795136, 0.13751945, 0.09453621, 0.21415663, 0.4896782 ,\n",
       "       0.07300855, 0.07501352, 0.88285079, 0.91388652, 0.96284929,\n",
       "       0.21008394, 0.14538464, 0.57616515, 0.25624812, 0.71181645,\n",
       "       0.75807128, 0.69124966, 0.91271179, 0.9330838 , 0.08617763,\n",
       "       0.46274082, 0.79436064, 0.23489344, 0.19446548, 0.61291802,\n",
       "       0.58153501, 0.60519399, 0.09178012, 0.23963215, 0.88931552,\n",
       "       0.14354871, 0.42607859, 0.3849254 , 0.65214408, 0.08603353,\n",
       "       0.10898097, 0.15746182, 0.7156612 , 0.72659784, 0.40979426,\n",
       "       0.89759891, 0.56906513, 0.22155153, 0.08018784, 0.08018784,\n",
       "       0.08017196, 0.44593014, 0.11835811, 0.87628779, 0.08273041,\n",
       "       0.06637298, 0.86154899, 0.25518631, 0.04368783, 0.11948633,\n",
       "       0.61642032, 0.13752547, 0.92750821, 0.31536738, 0.26542978,\n",
       "       0.1305979 , 0.10890103, 0.08374218, 0.11690064, 0.27349092,\n",
       "       0.4247027 , 0.74917233, 0.02376095, 0.50763474, 0.94711572,\n",
       "       0.33654384, 0.12143194, 0.8954275 , 0.48375379, 0.22264967,\n",
       "       0.40255304, 0.73143676, 0.12013172, 0.03825492, 0.02376095,\n",
       "       0.08614071, 0.52441851, 0.08694768, 0.08799998, 0.04584144,\n",
       "       0.9345315 , 0.06914925, 0.58349951, 0.88355458, 0.36153303,\n",
       "       0.47169981, 0.77007719, 0.5498997 , 0.09653313, 0.08598623,\n",
       "       0.08611179, 0.08614071, 0.20573957, 0.61262938, 0.12577254,\n",
       "       0.58796209, 0.12453964, 0.09850929, 0.10952231, 0.73653346,\n",
       "       0.9348073 , 0.45266444, 0.31417235, 0.19446548, 0.8819589 ,\n",
       "       0.25370344, 0.50605147, 0.69191573, 0.89950819, 0.72555566,\n",
       "       0.05179985, 0.61269556, 0.06458068, 0.61263841, 0.17704793,\n",
       "       0.39713704, 0.08652552, 0.17647403, 0.12830456, 0.70341619,\n",
       "       0.08028603, 0.11267167, 0.94039739, 0.23247531, 0.2170683 ,\n",
       "       0.05855833, 0.87313485, 0.04249827, 0.37856388, 0.38927763,\n",
       "       0.71584815, 0.84588531, 0.08598623, 0.44551693, 0.82413829,\n",
       "       0.89417675, 0.1256364 , 0.03775947, 0.04558081, 0.03515   ,\n",
       "       0.61263841, 0.12577254, 0.71982878, 0.05482527, 0.84799473,\n",
       "       0.65387546, 0.10242268, 0.0516667 , 0.11438806, 0.22324479,\n",
       "       0.41735838, 0.10866761, 0.61446063, 0.14486808, 0.973661  ,\n",
       "       0.77666675, 0.04997587, 0.14696559, 0.14034491, 0.66260577,\n",
       "       0.08533919, 0.61255122, 0.23498697, 0.13752547, 0.48842269,\n",
       "       0.8664436 , 0.18834027, 0.9423718 , 0.77983646, 0.22264967,\n",
       "       0.15205985, 0.06115224, 0.12577254, 0.10270259, 0.05661315,\n",
       "       0.08110835, 0.26019613, 0.68005882, 0.58327007, 0.71583782,\n",
       "       0.10909176, 0.13752096, 0.08614071, 0.9376936 , 0.32220429,\n",
       "       0.10941855, 0.75315738, 0.95052204, 0.32743672, 0.65459116,\n",
       "       0.51848991, 0.13716336, 0.94405531, 0.94339082, 0.69161463,\n",
       "       0.11637585, 0.94768288, 0.72287983, 0.08617763, 0.26036218,\n",
       "       0.70118589, 0.36305125, 0.4829233 , 0.24105582, 0.61990101,\n",
       "       0.77107929, 0.68061525, 0.9549186 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = train_predict[:,1]\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(train_preds)):\n",
    "    if(train_preds[i]>0.55):\n",
    "        train_preds[i] = 1\n",
    "    else:\n",
    "        train_preds[i] = 0\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training f1_score 0.7381443298969073\n"
     ]
    }
   ],
   "source": [
    "# Calculating f1-score\n",
    "k = f1_score(train_preds, train_y)\n",
    "print('Training f1_score', k )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128  16]\n",
      " [ 22  57]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf= confusion_matrix(test_y, test_predict)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       144\n",
      "           1       0.78      0.72      0.75        79\n",
      "\n",
      "    accuracy                           0.83       223\n",
      "   macro avg       0.82      0.81      0.81       223\n",
      "weighted avg       0.83      0.83      0.83       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report as rep\n",
    "print(rep( test_y , test_predict ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03398343,  0.00304106,  1.01509554,  0.13675569, -1.07274193,\n",
       "         1.18676102, -1.10765171,  0.82510034,  1.01804399,  0.32746763,\n",
       "        -0.65023871, -0.75657255, -0.27426065, -0.41043074,  0.11409976,\n",
       "         0.58535114, -0.19183298,  0.20030529, -0.33510241, -0.13453639,\n",
       "        -0.1591751 ,  0.13422668,  0.23551204, -0.29062941]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the coefficients\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Coefficient plot')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6), dpi=120, facecolor='w', edgecolor='b')\n",
    "x = range(len(train_x.columns))\n",
    "c = logreg.coef_.reshape(-1)\n",
    "plt.bar( x, c )\n",
    "plt.xlabel( \"Variables\")\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Coefficient plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.033983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.003041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>1.015096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.136756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>1.072742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable  coefficient\n",
       "0       Age     0.033983\n",
       "1      Fare     0.003041\n",
       "2  Pclass_1     1.015096\n",
       "3  Pclass_2     0.136756\n",
       "4  Pclass_3     1.072742"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coefficients = pd.DataFrame({\n",
    "    'Variable'    : train_x.columns,\n",
    "    'coefficient' : abs(c)\n",
    "})\n",
    "Coefficients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting variables with high coefficient\n",
    "sig_var = Coefficients[Coefficients.coefficient > 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>1.015096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>1.072742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>1.186761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>1.107652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SibSp_0</td>\n",
       "      <td>0.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SibSp_1</td>\n",
       "      <td>1.018044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SibSp_2</td>\n",
       "      <td>0.327468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SibSp_3</td>\n",
       "      <td>0.650239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SibSp_4</td>\n",
       "      <td>0.756573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SibSp_8</td>\n",
       "      <td>0.410431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Parch_1</td>\n",
       "      <td>0.585351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Parch_4</td>\n",
       "      <td>0.335102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variable  coefficient\n",
       "2     Pclass_1     1.015096\n",
       "4     Pclass_3     1.072742\n",
       "5   Sex_female     1.186761\n",
       "6     Sex_male     1.107652\n",
       "7      SibSp_0     0.825100\n",
       "8      SibSp_1     1.018044\n",
       "9      SibSp_2     0.327468\n",
       "10     SibSp_3     0.650239\n",
       "11     SibSp_4     0.756573\n",
       "13     SibSp_8     0.410431\n",
       "15     Parch_1     0.585351\n",
       "18     Parch_4     0.335102"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_8</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass_1  Pclass_3  Sex_female  Sex_male  SibSp_0  SibSp_1  SibSp_2  \\\n",
       "0         0         1           0         1        0        1        0   \n",
       "1         1         0           1         0        0        1        0   \n",
       "2         0         1           1         0        1        0        0   \n",
       "3         1         0           1         0        0        1        0   \n",
       "4         0         1           0         1        1        0        0   \n",
       "\n",
       "   SibSp_3  SibSp_4  SibSp_8  Parch_1  Parch_4  \n",
       "0        0        0        0        0        0  \n",
       "1        0        0        0        0        0  \n",
       "2        0        0        0        0        0  \n",
       "3        0        0        0        0        0  \n",
       "4        0        0        0        0        0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = data[sig_var['Variable'].values]\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with Cancer Data-set and and Probability Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "cancer_df=pd.DataFrame(cancer.data,columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainc, X_testc, y_trainc, y_testc = train_test_split(cancer.data, cancer.target, test_size=0.3, stratify=cancer.target, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VigneshSS\\Anaconda3\\envs\\new_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerclf = LogReg()\n",
    "cancerclf.fit(X_trainc, y_trainc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.58587084e-02 9.44141292e-01]\n",
      " [8.05247529e-03 9.91947525e-01]\n",
      " [9.99947378e-01 5.26224754e-05]\n",
      " [5.10379527e-02 9.48962047e-01]\n",
      " [9.70099061e-01 2.99009392e-02]\n",
      " [3.46960477e-01 6.53039523e-01]\n",
      " [9.99697131e-01 3.02869015e-04]\n",
      " [8.71978835e-04 9.99128021e-01]\n",
      " [9.99997376e-01 2.62360322e-06]]\n"
     ]
    }
   ],
   "source": [
    "probac = cancerclf.predict_proba(X_testc)\n",
    "print(probac[1:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = cancerclf.predict(X_testc)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.005305\n",
      "1  0.055859\n",
      "2  0.008052\n",
      "3  0.999947\n",
      "4  0.051038\n",
      "5  0.970099\n",
      "6  0.346960\n",
      "7  0.999697\n",
      "8  0.000872\n",
      "9  0.999997\n"
     ]
    }
   ],
   "source": [
    "probability = probac[:,0]\n",
    "prob_df = pd.DataFrame(probability)\n",
    "print(prob_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df['predict'] = np.where(prob_df[0]>=0.90, 1, 0)# create a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0  predict\n",
      "0    0.005305        0\n",
      "1    0.055859        0\n",
      "2    0.008052        0\n",
      "3    0.999947        1\n",
      "4    0.051038        0\n",
      "..        ...      ...\n",
      "166  0.903403        1\n",
      "167  1.000000        1\n",
      "168  0.004179        0\n",
      "169  0.008878        0\n",
      "170  0.052353        0\n",
      "\n",
      "[171 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(prob_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://towardsdatascience.com/logit-of-logistic-regression-understanding-the-fundamentals-f384152a33d1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
